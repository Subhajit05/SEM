---
title: "Fit Index"
author: "Subhajit Chattopadhyay"
date: "11/21/2020"
output: html_document
---

<link href = "E:/Mine/Books/IT/R-programming/Outline - R Programming/WD/SEM/SEM.css">


<h3>Discrepancy Function</h3>

<p> There are various fitness functions which stems out of the fact that there are various versions of Discrepancy function </p>

<p> The discrepancy function is nothing  but the square of the **difference between the observed and the implied covariance**</p>

<p> In matrix terms this *discrepancy function* is known as $(s - c) * W * (s - c)^\prime$ , where 's' and 'c' refer to the non-dupicate elements of of the observed covariance(S) and implied covaraince (C) matrix.</p>

<p> The discrepancy function can also be wriitent as follows - $$ \frac{1}{2} * [tr(S - C) * V]^2,  $$ 

<p> if, 

<ul>

<li> if V = I (identity matrix) - OLS estimation </li>

<li> if V = $S^{-1}$ - generalised least square </li>

<li> if V = $C^{-1}$ - maximum likelihood </li>

</ul>

</p>

<p> there is an alternative version for ML , which is $ln|c| - ln|S| - tr(SC^{-1}) - m $ - though the models are not exactly same , but as move in the same direction. </p>

<p> In terms of computation cost OLS is very fast followed by GLS and then come ML </p>

<h3> Computation - Discrepancy function</h3>

```{r}

S = matrix(data=c(2,1,1,4), nrow = 2)

C1 = matrix(data=c(2,1,1,4.01), nrow = 2)

C2 = matrix(data=c(2,1,1,3.99), nrow = 2)

S; C1;C2

S1_inv = solve(S)

S1_inv

C1_inv = solve(C1)
C2_inv = solve(C2)

C1_inv
C2_inv

diff1 = S - C1

diff2 = S - C2

diff1

diff2

library(psych)

(1/2) * tr((diff1 * diag(2))^2) # - OLS

(1/2) * tr((diff1 * S1_inv)^2) # - GLS

(1/2) * tr(diff1 * C1_inv)^2 # - ML


```


<h3>$\chi^2$ Test </h3>

<p>For GLS or ML one can multiply the criterion at the point of best fit by (N − 1 )to obtain an approximate $\chi^2$ value in large samples.</p>


<p>The $\chi^2$  can be used to test the fit of the implied C to S. The degrees of freedom (df ) for the comparison are the number of independent values in S less the number of unknowns used in generating C.</p>


<img src = "E:/Mine/Books/IT/R-programming/Outline - R Programming/WD/SEM/Presentation1/Slide27.png">

<p>In the above image there are 6 in  independent values in S (the three variances in the diagonal and the three covariances on one side of it). There were four unknowns being estimated, a, b, c, and d. So there are 2 df for a $\chi^2$ test.</p>

```{r}

library(psych)

ST = matrix(c(6.13,6.12,4.78,6.12,8.29,5.85,4.78,5.85,7.35), nrow = 3, byrow = T)

CT =  matrix(c(6.46, 5.66, 5.66,5.66,7.11,5.66,5.66,5.66,8.46), nrow = 3, byrow = T)


inv_CT = solve(CT)

DIFF_T = ST - CT

DIFF_T

ML = (1/2) * tr(((ST - CT) %*% inv_CT)^2)

ML

# Chi^2 equivalence 


criticl_value = qchisq(0.95, df = 2)

# if N = 110, then 
chi_equi = 110 * ML

chi_equi > criticl_value

# this shows that there is substantial difference between ST and CT. 

qchisq(.95,df = 1)
qchisq(.5, df = 2)

```


<h3>Hierarchial Models - Comparisons of Models</h3>

<img src = "E:/Mine/Books/IT/R-programming/Outline - R Programming/WD/SEM/Presentation1/Slide28.png" height = "700" width = "600">

<ul>

<li> Hierarchical relationship is established when some of the path coefficients are fixed </li>

<li> In the above diagramme , one can find that all the models from (2) to (7) has been derived from model no . (1)</li>


<li>Similary model (6) and (7) can be derived from model no (5). </li>

<li>When such hierarchy exists then one can look at the differential $\chi^2$ values to compare the models.But heirarchical raltionship does not exist between (3) and (6). </li>

</ul>



<h3>Fit Index - SEM</h3>

<ul>

<li>$\chi^2$ - (N - 1) * F - not significant values indicate better fit</li>

<li> Normed Fit Index(NFI) - $1 - \frac{F_k}{F_b}$ - Values closer to 1 indicate better fit. </li>

<li> Goodness of Fit (GFI) - $1 - \frac{F_k}{F_b}$ - Values closer to 1 indicate better fit.</li>


<li>Parsimony Normed Fit Index (PNFI) - $\frac{df_k}{df_b} * NFI$ - Goodness of Fit (GFI) - $1 - \frac{F_k}{F_b}$ - Values closer to 1 indicate better fit. </li>


<li> Adjusted Goodness of Fit Index (AGNFI) - $1 - (\frac{F_k}{F_s} * \frac{df_s}{df_k - Goodness of Fit (GFI) - $1 - \frac{F_k}{F_b}$ - Values closer to 1 indicate better fit.</li>

<li>Akaike's Information Criteria(AIC) - \chi^2 + 2 * q (no. of parameters) - smaller the values better is the fit</li>

<li> Expected Cross-validation Index(ECVI) - $F_K + \frac{2 * q}{N - m - 2}$ - smaller the value better is the fit</li>

<li>Nocentrality Parameter for $\chi^2$ - $\chi^2 - df$ - smaller the values better is the fit</li>

<li>Rescaled Noncentrality Parameter (RNI) - $\frac{(\chi^2 - df)}{(N-1}$ - smaller the values better is the fit

<li> Relative Non-centrality Index (RNI) $1 - \frac{d_k}{d_b}$ - Values closer to 1 indicate better fit.</li>

<li> Gamma Hat ($\Gamma_1$) - $\frac{m}{m + 2 * d_k}$ - Values closer to 1 indicate better fit.</li>

<li> Centrality Index (CI) - $exp(-(1/2)* d_k)$ - Values closer to 1 indicate better fit.</li>

<li> Non-normed Fit Index(NFI) , Tucker Lewis Index (TLI) - $ 1 - \frac{d_k}{d_b} * \frac{df_b}{df_k}$ - Values closer to 1 indicate better fit.</li>

<li> Root Mean Sqaure Error of Approximation (RMSEA) - \sqrt\frac{d_k}{df_k} - Values closer to 0 indicate better fit. </li>

<li>Comparative Fit Index - RNI (max =1 , min = 0) - Values closer to 1 indicate better fit.</li>

</ul>

<h3>Types of Fit Index </h3>

<ul>

<li> Abosulte Fit Indices - ($\chi^2$, GFI, AGFI, AIC, BIC, RMR, SRMR) - Absolute fit indices do not use an alternative model as a base for comparison. They are simply derived
from the fit of the obtained and implied covariance matrices . <li>


<li> Relative Fit Indices - (IIFL, TLI, NFI) - Relative fit indices compare a chi-square for the model tested to one from a so-called null model (also
called a “baseline” model or “independence” model). The null model is a model in which all measured
variables are uncorrelated (there are no latent variables).</li>

<li>Parsimonious Fit Indices - (PGFI, PNFI, PCFI) - Parsimony-corrected fit indices are relative fit indices that are adjustments to most of the fit indices
mentioned above. The adjustments are to penalize models that are less parsimonious, so that simpler
theoretical processes are favored over more complex ones. </li>

<li>Non-centrality Based Indices - (RMSEA, CFI, RNI,CI)</li>

</ul>



<p> The various overall fit indices which have been proposed tend to fall into two categories: 

<ul>

<li> those that simply describe goodness of fit,</li>

<li> and those that involve considerations of parsimony (i.e., that take into account the number of unknowns used to achieve that fit). A model reaching a particular level of fit while solving for fewer free
parameters would show as superior on an index of the latter kind.</li>

</ul>



```{r , messages=F}

library(lavaan)
library(semPlot)
library(psych)
library(psychTools)

test3 <- lavaan::HolzingerSwineford1939
test4 <- lavaan::PoliticalDemocracy


View(test3)

str(test4)







model2 <- '

# factors 

           eco60 =~ x1 + x2 + x3
           
           pol60 =~ y1 + y2 + y3 + y4
           
           pol65 =~ y5 + y6 + y7 + y8

# regressions

          pol60 ~ eco60 
        
          pol65 ~ eco60 + pol60 '


fit1 <- sem(model= model2, data = test4)

fitMeasures(fit1, fit.measures = "all")


```




```{r}
model3 <- '
  # measurement model
    ind60 =~ x1 + x2 + x3
    dem60 =~ y1 + y2 + y3 + y4
    dem65 =~ y5 + y6 + y7 + y8
  # regressions
    dem60 ~ ind60
    dem65 ~ ind60 + dem60
  # residual correlations
    y1 ~~ y5
    y2 ~~ y4 + y6
    y3 ~~ y7
    y4 ~~ y8
    y6 ~~ y8'


fit2 <- sem(model = model3, data = test4)

fitmeasures(fit2, baseline.model = fit1, output = "matrix") # this 

semPaths(fit2)

anova(fit1, fit2)

```









